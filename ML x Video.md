---
title: ML x Video
---

Here we will show how [[Machine Learning]] (ML) can be applied on the **moving image** (video, film). It's about generating and manipulating images or whole video sequences. There are possible use cases in the field of media art, cinema, storytelling, video installations, music videos, GIF memes, and more!

## Useful operations on images

The following capabilities will most probably be integrated in popular image and video editing tools very soon.. Will we still call them "AI" then? ü§î

### ‚ùáÔ∏è Greenscreening

<img src="https://raw.githubusercontent.com/burglabs/knowledge-xlab/main/assets/media/runway-greenscreening.gif" alt="A screenshot of the software RunwayML" width="300"/>
How to greenscreen a video with the software [RunwayML](https://runwayml.com/resources/how-to-green-screen-a-video/)

### ‚ùáÔ∏è Recoloring

<iframe width="300" height="200" src="https://www.youtube.com/embed/1y-aj7uy2WY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

### ‚ùáÔ∏è Upscaling

<iframe width="300" height="200" src="https://www.youtube.com/embed/OI-To1eUtuU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
This classic video made in 1994 has been upscaled in 2021 from 480p to 1440p with Machine Learning

### ‚ùáÔ∏è 2D to 3D

![Parallax effect on Instagram by Cyril Diagne](https://raw.githubusercontent.com/burglabs/knowledge-xlab/main/assets/media/cyril-diagne-2d3d.gif)

Machine Learning can infer depth information from a 2D image. With this information you can add various 3D effects to images, like this parallax effect made by [Cyril Diagne](https://github.com/cyrildiagne/instagram-3d-photo)

ü§î Some of these examples seem "magic" because they create more out of less: adding color information, increasing resolution, adding depth... But keep in mind that Machine Learning is based on statistics, the algorithms have "learned" from large amount of example footage what the probabilities for a specific depth/color/shape are. That makes them susceptible for [[bias]]. Keep that in mind when you work with these apparently objective tools!

## Deepfakes

A deepfake is when you "puppeteer" a target video (most often of a human being) with a source video. Here are a few examples:

<iframe width="600" height="383" src="https://www.youtube.com/embed/dCTM2lvm0QE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

Sassy Justice is a Youtube series made by the makers of South Park. Watch the full series [here](https://www.youtube.com/c/SassyJustice/videos)!

Here's a real-time example, "First order Kiss" by [Shardcore](http://www.shardcore.org/). He writes: "I tried lip-sync‚Äôing to [Prince](https://en.wikipedia.org/wiki/Kiss_(Prince_song)) via [Avatarify](https://github.com/alievk/avatarify) and recording the results. Frame-rate is a bit crappy, but not bad for ‚Äòreal-time-processing‚Äô The future of karaoke, perhaps?"

<iframe src="https://player.vimeo.com/video/420596414?h=0f08061b90" width="300" height="300" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>


Here's a piece of video art by British artist [Libby Heaney](http://libbyheaney.co.uk) in which she plays with gender roles by becoming Elvis herself..

<iframe width="600" height="383" src="https://www.youtube.com/embed/CXMgfZEP2cA?list=TLGGpPagydLuJDQxMDAxMjAyMg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## New kinds of filters

Horse2Zebra (made with [CycleGAN](https://github.com/junyanz/CycleGAN))

![A running horse is turned into a running zebra](https://raw.githubusercontent.com/burglabs/knowledge-xlab/main/assets/media/horse2zebra.gif)

<iframe src="https://player.vimeo.com/video/260612034?h=1cf903469e" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
In "Gloomy Sunday" artist [Memo Akten](http://www.memo.tv/works/) plays with every day objects infront of the camera and turns them with ML into almost realistic images of waves and other nature phenomena.

ü§î As you can see these new kind of "filters" are doing more than just manipulating the "style" of an image, they seem to somehow manipulate the "semantics" of an image as well!



## Latent Space Walks

The [[latent space]] is a high dimensional mathematical space of possible representations (depending on your training data) that can be navigated. By walking the latent space we can create animations of organic change.

<iframe src="https://player.vimeo.com/video/520039359?h=06911ac0de" width="640" height="480" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
<p><a href="https://vimeo.com/520039359">Latent Riot Space Walk</a> from <a href="https://vimeo.com/movingtargetcollective">Moving Target Collective</a> on <a href="https://vimeo.com">Vimeo</a>.</p>

## Help with editing (and even storytelling?)

ML can also be used to assist you in the editing process by analysing your footage according to specific parameters (objects in the shot, angle, lightning, scenery, etc.)

### Kaspar.ai

https://www.kasparai.com/

Here's an interview with the makers of Kaspar.ai:
...

## More inspiration

<iframe
    border=0
    frameborder=0
    height=250
    width="auto" 
    display="inline"
    src="https://twitframe.com/show?url=https://twitter.com/RiversHaveWings/status/1447708268789338119
">
</iframe>

<iframe
    border=0
    frameborder=0
    height=250
    width="auto"
    display="inline"
    src="https://twitframe.com/show?url=https://twitter.com/Buntworthy/status/1440244134724308995
">
</iframe>

<iframe
    border=0
    frameborder=0
    height=250
    width="auto"
    display="inline"
    src="https://twitframe.com/show?url=https://twitter.com/unltd_dream_co/status/1469085102500163584

">

</iframe>

<iframe
    border=0
    frameborder=0
    height=250
    width="auto"
    display="inline"
    src="https://twitframe.com/show?url=https://twitter.com/chigozienri/status/1417957701087281162
">
</iframe>

<iframe width="100%" height="auto" src="https://www.youtube.com/embed/5dfCmSY8Ws0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe
    border=0
    frameborder=0
    height=250
    width="auto"
    display="inline"
    src="https://twitframe.com/show?url=https://twitter.com/xsteenbrugge/status/1466519092916019204
">
</iframe>

<iframe
    border=0
    frameborder=0
    height=250
    width="auto"
    display="inline"
    src="https://twitframe.com/show?url=https://twitter.com/ak92501/status/1463691106416214019
">
</iframe>

![Very realistic looking AI generated street scene video](https://raw.githubusercontent.com/burglabs/knowledge-xlab/main/assets/media/streetscene-aigenerated.gif)

Image from this 2018 article: https://www.technologyreview.com/2018/12/03/138834/ai-software-can-dream-up-an-entire-digital-world-from-a-simple-sketch/

## Tools

- RunwayML
- Avatarify
- Kaspar.ai

## More links

Check out [Alexa](https://twitter.com/alexabruck)'s are.na Board [here](https://www.are.na/alexa-steinbruck/ml-x-video-film) where she regularly dumps interesting things she finds on the internet
